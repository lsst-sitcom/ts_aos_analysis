{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WET-013: WEP Performance as a function of exposure time\n",
    "\n",
    "Owner: **Bryce Kalmbach** [@jbkalmbach](https://github.com/lsst-sitcom/sitcomtn-133/issues/new?body=@jbkalmbach) <br>\n",
    "Last Verified to Run: **2024-10-17** <br>\n",
    "Software Version:\n",
    "  - `ts_wep`: **12.0.0**\n",
    "  - `lsst_distrib`: **w_2024_42**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Description\n",
    "\n",
    "This test will look at the WEP output from multiple defocal visits across a range of exposure times to investigate if increasing exposure time helps average out the atmospheric residuals.\n",
    "We will calculate the average Zernikes for each visit and then find the variation in the estimates of the Zernikes from estimates on visits with the same exposure time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from lsst.daf.butler import Butler\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from IPython.utils import io\n",
    "from lsst.ts.wep.task.pairTask import ExposurePairer, ExposurePairerConfig\n",
    "from lsst.ts.wep.utils import convertZernikesToPsfWidth\n",
    "from astropy.table import Table, QTable, unique\n",
    "from scipy.optimize import curve_fit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to appropriate butler when on-sky images arrive\n",
    "path_to_aos_butler = '/sdf/data/rubin/repo/aos_imsim/'\n",
    "butler = Butler(path_to_aos_butler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Zernike Estimates\n",
    "\n",
    "When running exposure time tests we will run the Wavefront Estimation Pipeline (WEP) on the images. \n",
    "Once this is done all we need is the collection name used when running the pipeline and we can generate our analysis using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'WET-013/directDetectCatalog_RefitWcs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data ids from the collection with the WEP output\n",
    "data_ids = list(butler.registry.queryDataIds(('exposure', 'visit', 'detector'), collections=collection_name, datasets='zernikeEstimateAvg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather exposure time for each output by looking at the `visitInfo` for each exposure.\n",
    "print(butler.get('postISRCCD.visitInfo', dataId=data_ids[0], collections=collection_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZernAvgFromTable(table, z_min=4, z_max=29):\n",
    "    \"\"\"Gather the average zernikes in microns from the zernikes table into a single numpy array\"\"\"\n",
    "    avg_row_idx = np.where(zern_table['label'] == 'average')\n",
    "    zern_avg = []\n",
    "    for z_num in range(z_min, z_max):\n",
    "        zern_avg.append(zern_table[f'Z{z_num}'].to(u.um)[avg_row_idx].value[0])\n",
    "    zern_avg = np.array(zern_avg)\n",
    "    return zern_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather relevant visit info and zernike outputs into an Astropy table\n",
    "exp_time_list = []\n",
    "airmass_list = []\n",
    "visit_list = []\n",
    "detector_list = []\n",
    "zern_avg_list = []\n",
    "for data_id in data_ids:\n",
    "    zern_table = butler.get('zernikes', dataId=data_id, collections=collection_name)\n",
    "    zern_avg_list.append(getZernAvgFromTable(zern_table))\n",
    "    visit_list.append(data_id['visit'])\n",
    "    detector_list.append(data_id['detector'])\n",
    "    visitInfo = butler.get('postISRCCD.visitInfo', dataId=data_id, collections=collection_name)\n",
    "    exp_time_list.append(visitInfo.exposureTime)\n",
    "    airmass_list.append(visitInfo.boresightAirmass)\n",
    "\n",
    "data_table = QTable([exp_time_list, visit_list, detector_list, airmass_list, zern_avg_list], names=['exp_time', 'visit', 'detector', 'airmass', 'zern_avg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure Time Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the dataset\n",
    "\n",
    "Just take a quick look at the various exposure times used in the data and the number of visits for each exposure time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comcam detector Ids\n",
    "detector_ids = np.arange(9)\n",
    "# Get exposure times directly from data set\n",
    "exp_times = np.unique(data_table['exp_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_time_counts = []\n",
    "for exp_time in exp_times:\n",
    "    exp_time_counts.append(np.sum(np.logical_and(data_table['exp_time'] == exp_time, data_table['detector'] == detector_ids[0])))\n",
    "plt.plot(exp_times, exp_time_counts, '-o')\n",
    "plt.title('Number of Visits with each exposure time')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.xlabel('Exposure Time (seconds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency of Mean Value across Exposure Times\n",
    "\n",
    "In this first plot we examine the mean value across the different runs. If we are in the same optical state during the different observations then we should see that the mean value will be approximately the same for each Zernike across the different exposure times. We can also separate it by detector to see if there are any effects on detectors with more vignetting than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12))\n",
    "exp_times = np.unique(data_table['exp_time'])\n",
    "for detector in range(9):\n",
    "    fig.add_subplot(3,3,detector+1)\n",
    "    det_table = data_table[data_table['detector'] == detector]\n",
    "    for exp_time in exp_times:\n",
    "        exp_time_table = det_table[det_table['exp_time'] == exp_time]\n",
    "        zern_avg_array = np.array(exp_time_table['zern_avg'].value)\n",
    "        plt.plot(np.arange(4, 29), convertZernikesToPsfWidth(np.mean(zern_avg_array, axis=0)), label=f'Exp Time {exp_time} sec')\n",
    "        plt.xlabel('Noll Index')\n",
    "        plt.ylabel('Zernike Estimate (arcsec)')\n",
    "        plt.title(f'Detector {detector}')\n",
    "    plt.legend(fontsize=8)\n",
    "plt.suptitle('Mean Zernike Estimate on ComCam sims across Exposure Times by detector')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "exp_times = np.unique(data_table['exp_time'])\n",
    "for exp_time in exp_times:\n",
    "    exp_time_table = data_table[data_table['exp_time'] == exp_time]\n",
    "    zern_avg_array = np.array(exp_time_table['zern_avg'].value)\n",
    "    plt.plot(np.arange(4, 29), convertZernikesToPsfWidth(np.mean(zern_avg_array, axis=0)), label=f'Exp Time {exp_time} sec')\n",
    "    plt.xlabel('Noll Index')\n",
    "    plt.ylabel('Zernike Estimate (arcsec)')\n",
    "    plt.legend(fontsize=8)\n",
    "plt.title('Mean Zernike Estimate on ComCam sims across Exposure Times averaged across all detectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability in the measurements for each Zernike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the means across each detector for each exposure time seem fairly consistent we can compare the variability in the measurements for each Zernike on each detector by plotting the standard deviation for each Zernike coefficient separated by the detectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12))\n",
    "for detector in range(9):\n",
    "    fig.add_subplot(3,3,detector+1)\n",
    "    det_table = data_table[data_table['detector'] == detector]\n",
    "    for exp_time in exp_times:\n",
    "        exp_time_table = det_table[det_table['exp_time'] == exp_time]\n",
    "        zern_std_array = np.array(exp_time_table['zern_avg'].value)\n",
    "        plt.plot(np.arange(4, 29), convertZernikesToPsfWidth(np.std(zern_std_array, axis=0)), label=f'Exp Time {exp_time} sec')\n",
    "        plt.xlabel('Noll Index')\n",
    "        plt.ylabel('Standard Deviation (arcsec)')\n",
    "        plt.title(f'Detector {detector}')\n",
    "    plt.legend(fontsize=8)\n",
    "plt.suptitle('Standard Deviation of the Zernike estimate across 4 runs at each exposure time', size=18)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above is rather busy and nothing really sticks out so the next thing to do is to combine all the measurements from all the detectors.\n",
    "However, each detector has a slightly different true value for each Zernike.\n",
    "In place of a true value we can subtract the mean value for each detector from each measurement and use this information to calculate a standard deviation across the whole camera.\n",
    "This translates mathematically to:\n",
    "\n",
    "$\\sigma_{camera} = \\sqrt{\\frac{1}{detectors*visits} \\sum \\limits^{detectors}_{i} \\sum \\limits^{visits}_{j} (x_{i,j} - \\overline{x}_{i})^{2}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "for exp_time in exp_times:\n",
    "    num_rows = 0\n",
    "    deviations = []\n",
    "    for detector in detector_ids:\n",
    "        use_rows = np.logical_and(data_table['exp_time'] == exp_time, data_table['detector'] == detector)\n",
    "        detector_table = data_table[use_rows]\n",
    "        deviations.append(detector_table['zern_avg'] - np.mean(detector_table['zern_avg'], axis=0))\n",
    "        num_rows += len(detector_table)\n",
    "    deviations = np.array(deviations).reshape(num_rows, 25)\n",
    "    zern_std_array = np.sqrt(1 / (len(deviations)) * np.sum(np.square(deviations), axis=0))\n",
    "    plt.plot(np.arange(4, 29), convertZernikesToPsfWidth(zern_std_array), label=f'Exp Time {exp_time} sec')\n",
    "    plt.xlabel('Noll Index')\n",
    "    plt.ylabel('Standard Deviation  (arcsec)')\n",
    "    plt.legend(fontsize=8)\n",
    "plt.title('Standard Deviation across 4 runs at each exposure time across all detectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the general expected trend of the variation decreasing with increased exposure time.\n",
    "Below we plot just the values at 10, 30, and 90 seconds to make the trend clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "for exp_time in [10, 30, 90]:\n",
    "    num_rows = 0\n",
    "    deviations = []\n",
    "    for detector in detector_ids:\n",
    "        use_rows = np.logical_and(data_table['exp_time'] == exp_time, data_table['detector'] == detector)\n",
    "        detector_table = data_table[use_rows]\n",
    "        deviations.append(detector_table['zern_avg'] - np.mean(detector_table['zern_avg'], axis=0))\n",
    "        num_rows += len(detector_table)\n",
    "    deviations = np.array(deviations).reshape(num_rows, 25)\n",
    "    zern_std_array = np.sqrt(1 / (len(deviations)) * np.sum(np.square(deviations), axis=0))\n",
    "    plt.plot(np.arange(4, 29), convertZernikesToPsfWidth(zern_std_array), label=f'Exp Time {exp_time} sec')\n",
    "    plt.xlabel('Noll Index')\n",
    "    plt.ylabel('Standard Deviation (arcsec)')\n",
    "    plt.legend(fontsize=8)\n",
    "plt.title('Standard Deviation across 4 runs at each exposure time across all detectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we look at the same information but take a cross section across each individual Zernike coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zern_std_exp_times_all = []\n",
    "for exp_time in exp_times:\n",
    "    num_rows = 0\n",
    "    deviations = []\n",
    "    for detector in detector_ids:\n",
    "        use_rows = np.logical_and(data_table['exp_time'] == exp_time, data_table['detector'] == detector)\n",
    "        detector_table = data_table[use_rows]\n",
    "        deviations.append(convertZernikesToPsfWidth(detector_table['zern_avg']) - np.mean(convertZernikesToPsfWidth(detector_table['zern_avg']), axis=0))\n",
    "        num_rows += len(detector_table)\n",
    "    deviations = np.array(deviations).reshape(num_rows, 25)\n",
    "    zern_std_array = np.sqrt(1 / (len(deviations)) * np.sum(np.square(deviations), axis=0))\n",
    "    zern_std_exp_times_all.append(zern_std_array)\n",
    "zern_std_exp_times_all = np.array(zern_std_exp_times_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx in range(25):\n",
    "    fig.add_subplot(5, 5, idx+1)\n",
    "    plt.scatter(exp_times, zern_std_exp_times_all[:, idx])\n",
    "    plt.xlabel('Exp Time (sec)')\n",
    "    plt.ylabel('Std. Dev. (arcsec)')\n",
    "    plt.title(f'Z{idx+4}')\n",
    "plt.suptitle('Standard Deviation as function of exposure time')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can plot a fit and display the fit coefficients as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx in range(25):\n",
    "    fig.add_subplot(5, 5, idx+1)\n",
    "    plt.scatter(exp_times, zern_std_exp_times_all[:, idx]**2)\n",
    "\n",
    "    def fit_func(x, a, c):\n",
    "        x0 = exp_times[0]\n",
    "        return c * ((x/x0)**a)\n",
    "\n",
    "    fit_exp, fit_var = curve_fit(fit_func, exp_times, zern_std_exp_times_all[:, idx]**2)\n",
    "\n",
    "    def fit_func_fixed_tm1(x, c):\n",
    "        x0 = exp_times[0]\n",
    "        return c * ((x/x0)**-1)\n",
    "\n",
    "    fit_exp_tm1, fit_var = curve_fit(fit_func_fixed_tm1, exp_times, zern_std_exp_times_all[:, idx]**2)\n",
    "    \n",
    "    plt.plot(exp_times, fit_exp_tm1[0]*(exp_times / exp_times[0])**-(1), label='t^-1')\n",
    "    plt.plot(exp_times, fit_exp[1]*(exp_times / exp_times[0])**fit_exp[0], label=f'Fit: t^{fit_exp[0]:.2f}')\n",
    "    plt.xlabel('Exp Time (sec)')\n",
    "    plt.ylabel('Variance ($arcsec^2$)')\n",
    "    plt.title(f'Z{idx+4}')\n",
    "    plt.legend()\n",
    "plt.suptitle('Variance as function of exposure time')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
